{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP0wktKLl/KXZZxBsKHYOA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luca-Skyline/check4mate/blob/main/Chess_Piece_CNN_Model_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10/29/2023 Luca DalCanto\n",
        "\n",
        "# Chess Piece Convolutional Neural Network (CNN)\n",
        "The code contained in this jupyter notebook was used to create the Deep Learning image classification model used in check4mate, an app in development by Luca DalCanto.\n",
        "\n",
        "This code uses YOLOv5, a leading Neural Network for object detection and segmentation, but uses it instead for image classification. A dataset with around 25000 images is loaded from Roboflow, with each image labeled as one of 13 classes (6 pieces of two colors, plus the \"empty square\" class). The \"medium\" size of YOLOv5 model is fit with this data over 40 epochs, and the .pt file is then exported for use in my app.\n",
        "\n",
        "### Data\n",
        "\n",
        "You can find the dataset I used on Roboflow: https://universe.roboflow.com/luca-dalcanto-lrlwg/chess-piece-detector-sv3nm/dataset/4. This is my Roboflow project, but the images themselves are attributed to someone else (see below).\n",
        "\n",
        "This data has been preprocessed and augmented with the following properties:\n",
        "\n",
        "*   Preprocessing: Grayscale\n",
        "*   Preprocessing: Resize to 224x224 pixels (this should not do anything with my particular dataset but it's a good safety)\n",
        "*   Augmentation: 90°, 180°, 270° Rotation\n",
        "*   Augmentation: Shear ±15° horizontal, vertical\n",
        "\n",
        "The preprocessing homogenizes the images, and the augmentation allows to have more images by duplicating some of the images with changes such as rotation and shear (the CNN needs to be able to identify a chess piece from any overhead angle).\n",
        "\n",
        "Data attributed to Daylen Yang under the Open Data Commons Attribution License: http://opendatacommons.org/licenses/by/1.0/.\n",
        "Thank you so much Daylen Yang!\n",
        "\n",
        "This data has been adapted for this specific dataset. By the nature of the Open Data Commons Attribution License, this \"new\" dataset found here is also protected by the same license. This means you can use this data, but you need to attribute and any modified form of the data must also be released under the same license.\n",
        "\n",
        "For more info on the raw data, please see Daylen Yang's github repo: https://github.com/daylen/chess-id\n",
        "\n",
        "Thanks! <br>\n",
        "Luca DalCanto, <br>\n",
        "Skyline High School, SLC, UT"
      ],
      "metadata": {
        "id": "xuM5MvoDjNQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t23YMrPsDKw",
        "outputId": "9ae05f11-4982-4bf2-a717-89fc38d87ada"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-231-gc2f131a Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 27.1/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we're in the right directory to download our custom dataset\n",
        "import os\n",
        "os.makedirs(\"../datasets/\", exist_ok=True)\n",
        "%cd ../datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltwOos0nsFws",
        "outputId": "0916b9dd-527f-484c-b899-15016b2f404e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## For safety reason, as this is a public colab, the API Key has been removed. To proceed, copy and paste the download code from Roboflow into this cell\n",
        "# https://universe.roboflow.com/luca-dalcanto-lrlwg/chess-piece-detector-sv3nm/dataset/4\n",
        "\n",
        "\n",
        "# !pip install roboflow\n",
        "\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"ENTER KEY HERE\")\n",
        "# project = rf.workspace(\"luca-dalcanto-lrlwg\").project(\"chess-piece-detector-sv3nm\")\n",
        "# dataset = project.version(4).download(\"folder\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DkQGDwIvsIkE",
        "outputId": "35c11665-576b-446a-ac58-4872c2020f13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.16.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.43.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.3)\n",
            "Installing collected packages: python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.8.1.78\n",
            "    Uninstalling opencv-python-headless-4.8.1.78:\n",
            "      Successfully uninstalled opencv-python-headless-4.8.1.78\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.7 supervision-0.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cv2",
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Chess-Piece-Detector-4 to folder:: 100%|██████████| 104723/104723 [00:01<00:00, 62479.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Chess-Piece-Detector-4 in folder:: 100%|██████████| 24973/24973 [00:03<00:00, 7529.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the dataset name to the environment so we can use it in a system call later\n",
        "dataset_name = dataset.location.split(os.sep)[-1]\n",
        "os.environ[\"Chess-Piece-Detector-4\"] = dataset_name"
      ],
      "metadata": {
        "id": "Qo0nMZOCsX2H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../yolov5\n",
        "!python classify/train.py --model yolov5m-cls.pt --data Chess-Piece-Detector-4 --epochs 40 --img 224 --pretrained weights/yolov5m-cls.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz6Dk1UKsvwJ",
        "outputId": "97a8538f-4304-4c18-fae6-b92f657e911c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2023-10-29 21:19:14.655441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-29 21:19:14.655497: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-29 21:19:14.655534: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5m-cls.pt, data=Chess-Piece-Detector-4, epochs=40, batch_size=64, imgsz=224, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=weights/yolov5m-cls.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-231-gc2f131a Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m-cls.pt to yolov5m-cls.pt...\n",
            "100% 24.9M/24.9M [00:00<00:00, 139MB/s] \n",
            "\n",
            "Model summary: 212 layers, 11693293 parameters, 11693293 gradients, 30.9 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 46 weight(decay=0.0), 47 weight(decay=5e-05), 47 bias\n",
            "Image sizes 224 train, 224 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-cls/exp2\u001b[0m\n",
            "Starting yolov5m-cls.pt training on Chess-Piece-Detector-4 dataset with 13 classes for 40 epochs...\n",
            "\n",
            "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
            "      1/40     2.26G         1.5        1.68       0.598       0.962: 100% 357/357 [01:26<00:00,  4.15it/s]\n",
            "      2/40     2.81G        1.29         2.6       0.399        0.73: 100% 357/357 [01:25<00:00,  4.20it/s]\n",
            "      3/40     2.81G        1.23        1.38       0.638       0.942: 100% 357/357 [01:25<00:00,  4.16it/s]\n",
            "      4/40     2.81G        1.16         1.7       0.575       0.881: 100% 357/357 [01:26<00:00,  4.12it/s]\n",
            "      5/40     2.81G         1.1         1.1       0.754       0.995: 100% 357/357 [01:25<00:00,  4.18it/s]\n",
            "      6/40     2.81G        1.03        1.15        0.78       0.995: 100% 357/357 [01:24<00:00,  4.22it/s]\n",
            "      7/40     2.81G       0.984       0.823       0.881           1: 100% 357/357 [01:25<00:00,  4.17it/s]\n",
            "      8/40     2.81G       0.951        1.03       0.803       0.996: 100% 357/357 [01:24<00:00,  4.21it/s]\n",
            "      9/40     2.81G       0.928       0.797       0.925           1: 100% 357/357 [01:24<00:00,  4.24it/s]\n",
            "     10/40     2.81G       0.898       0.851       0.873       0.997: 100% 357/357 [01:23<00:00,  4.25it/s]\n",
            "     11/40     2.81G       0.883       0.824       0.887       0.994: 100% 357/357 [01:24<00:00,  4.23it/s]\n",
            "     12/40     2.81G       0.862       0.775       0.926       0.999: 100% 357/357 [01:23<00:00,  4.28it/s]\n",
            "     13/40     2.81G       0.848       0.852       0.876       0.992: 100% 357/357 [01:23<00:00,  4.26it/s]\n",
            "     14/40     2.81G       0.843       0.696       0.956       0.999: 100% 357/357 [01:25<00:00,  4.20it/s]\n",
            "     15/40     2.81G       0.821       0.653       0.964           1: 100% 357/357 [01:24<00:00,  4.21it/s]\n",
            "     16/40     2.81G       0.809       0.663       0.957           1: 100% 357/357 [01:23<00:00,  4.27it/s]\n",
            "     17/40     2.81G       0.796       0.654       0.972           1: 100% 357/357 [01:24<00:00,  4.24it/s]\n",
            "     18/40     2.81G       0.784       0.621       0.979           1: 100% 357/357 [01:24<00:00,  4.24it/s]\n",
            "     19/40     2.81G        0.78       0.625       0.977           1: 100% 357/357 [01:23<00:00,  4.25it/s]\n",
            "     20/40     2.81G       0.767       0.612       0.983           1: 100% 357/357 [01:24<00:00,  4.23it/s]\n",
            "     21/40     2.81G       0.766       0.593       0.991           1: 100% 357/357 [01:23<00:00,  4.28it/s]\n",
            "     22/40     2.81G       0.754       0.611       0.979           1: 100% 357/357 [01:23<00:00,  4.28it/s]\n",
            "     23/40     2.81G       0.745       0.587       0.987           1: 100% 357/357 [01:23<00:00,  4.27it/s]\n",
            "     24/40     2.81G        0.74       0.584        0.99           1: 100% 357/357 [01:24<00:00,  4.21it/s]\n",
            "     25/40     2.81G        0.73       0.578       0.995           1: 100% 357/357 [01:24<00:00,  4.23it/s]\n",
            "     26/40     2.81G       0.725       0.577       0.994           1: 100% 357/357 [01:23<00:00,  4.27it/s]\n",
            "     27/40     2.81G       0.717       0.579       0.995           1: 100% 357/357 [01:23<00:00,  4.26it/s]\n",
            "     28/40     2.81G        0.71        0.57       0.997           1: 100% 357/357 [01:24<00:00,  4.21it/s]\n",
            "     29/40     2.81G       0.707       0.571       0.995           1: 100% 357/357 [01:24<00:00,  4.22it/s]\n",
            "     30/40     2.81G       0.703        0.57       0.997           1: 100% 357/357 [01:24<00:00,  4.24it/s]\n",
            "     31/40     2.81G       0.688        0.57       0.996           1: 100% 357/357 [01:25<00:00,  4.20it/s]\n",
            "     32/40     2.81G       0.685       0.566       0.996           1: 100% 357/357 [01:25<00:00,  4.17it/s]\n",
            "     33/40     2.81G       0.683       0.565       0.998           1: 100% 357/357 [01:24<00:00,  4.24it/s]\n",
            "     34/40     2.81G       0.677       0.563       0.998           1: 100% 357/357 [01:24<00:00,  4.24it/s]\n",
            "     35/40     2.81G       0.671       0.562       0.998           1: 100% 357/357 [01:23<00:00,  4.27it/s]\n",
            "     36/40     2.81G       0.659       0.561       0.999           1: 100% 357/357 [01:24<00:00,  4.20it/s]\n",
            "     37/40     2.81G       0.661        0.56       0.999           1: 100% 357/357 [01:23<00:00,  4.30it/s]\n",
            "     38/40     2.81G       0.653        0.56       0.999           1: 100% 357/357 [01:23<00:00,  4.30it/s]\n",
            "     39/40     2.81G       0.649        0.56       0.999           1: 100% 357/357 [01:23<00:00,  4.26it/s]\n",
            "     40/40     2.81G       0.643       0.559       0.999           1: 100% 357/357 [01:24<00:00,  4.25it/s]\n",
            "\n",
            "Training complete (0.942 hours)\n",
            "Results saved to \u001b[1mruns/train-cls/exp2\u001b[0m\n",
            "Predict:         python classify/predict.py --weights runs/train-cls/exp2/weights/best.pt --source im.jpg\n",
            "Validate:        python classify/val.py --weights runs/train-cls/exp2/weights/best.pt --data /content/datasets/Chess-Piece-Detector-4\n",
            "Export:          python export.py --weights runs/train-cls/exp2/weights/best.pt --include onnx\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp2/weights/best.pt')\n",
            "Visualize:       https://netron.app\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights /content/yolov5/runs/train-cls/exp2/weights/best.pt --source /content/somePiece.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzjKQfvRs8mF",
        "outputId": "6d412d49-d2e5-40da-d6fa-8a33bd764a57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['/content/yolov5/runs/train-cls/exp2/weights/best.pt'], source=/content/somePiece.png, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-231-gc2f131a Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 166 layers, 11682845 parameters, 0 gradients, 30.6 GFLOPs\n",
            "image 1/1 /content/somePiece.png: 224x224 bn 0.44, bp 0.12, br 0.10, bq 0.08, bk 0.07, 5.9ms\n",
            "Speed: 0.4ms pre-process, 5.9ms inference, 8.2ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdJFqwVTUpjz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}