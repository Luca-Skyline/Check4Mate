{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIBG7PdQEBpF11rO3eC75y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luca-Skyline/check4mate/blob/main/Chess_Piece_CNN_Model_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10/29/2023 Luca DalCanto\n",
        "\n",
        "# Chess Piece Convolutional Neural Network (CNN)\n",
        "The code contained in this jupyter notebook was used to create the Deep Learning image classification model used in check4mate, an app in development by Luca DalCanto.\n",
        "\n",
        "This code uses YOLOv5, a leading Neural Network for object detection and segmentation, but uses it instead for image classification. A dataset with around 25000 images is loaded from Roboflow, with each image labeled as one of 13 classes (6 pieces of two colors, plus the \"empty square\" class). The \"medium\" size of YOLOv5 model is fit with this data over 40 epochs, and the .pt file is then exported for use in my app.\n",
        "\n",
        "### Data\n",
        "\n",
        "You can find the dataset I used on Roboflow: https://universe.roboflow.com/luca-dalcanto-lrlwg/chess-piece-detector-sv3nm/dataset/4. This is my Roboflow project, but the images themselves are attributed to someone else (see below).\n",
        "\n",
        "This data has been preprocessed and augmented with the following properties:\n",
        "\n",
        "*   Preprocessing: Grayscale\n",
        "*   Preprocessing: Resize to 224x224 pixels (this should not do anything with my particular dataset but it's a good safety)\n",
        "*   Augmentation: 90Â°, 180Â°, 270Â° Rotation\n",
        "*   Augmentation: Shear Â±15Â° horizontal, vertical\n",
        "\n",
        "The preprocessing homogenizes the images, and the augmentation allows to have more images by duplicating some of the images with changes such as rotation and shear (the CNN needs to be able to identify a chess piece from any overhead angle).\n",
        "\n",
        "Data attributed to Daylen Yang under the Open Data Commons Attribution License: http://opendatacommons.org/licenses/by/1.0/.\n",
        "Thank you so much Daylen Yang!\n",
        "\n",
        "This data has been adapted for this specific dataset. By the nature of the Open Data Commons Attribution License, this \"new\" dataset found here is also protected by the same license. This means you can use this data, but you need to attribute and any modified form of the data must also be released under the same license.\n",
        "\n",
        "For more info on the raw data, please see Daylen Yang's github repo: https://github.com/daylen/chess-id\n",
        "\n",
        "Thanks! <br>\n",
        "Luca DalCanto, <br>\n",
        "Skyline High School, SLC, UT"
      ],
      "metadata": {
        "id": "xuM5MvoDjNQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t23YMrPsDKw",
        "outputId": "76f0df0b-c851-409b-d2ee-961d4cb7c99e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-283-g875d9278 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.9/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we're in the right directory to download our custom dataset\n",
        "import os\n",
        "os.makedirs(\"../datasets/\", exist_ok=True)\n",
        "%cd ../datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltwOos0nsFws",
        "outputId": "057514b5-9b6c-4d8a-e5e1-a253f3767c40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## For safety reason, as this is a public colab, the API Key has been removed. To proceed, copy and paste the download code from Roboflow into this cell\n",
        "# https://universe.roboflow.com/luca-dalcanto-lrlwg/chess-piece-detector-sv3nm/dataset/4\n",
        "\n",
        "\n",
        "# !pip install roboflow\n",
        "\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"INSERT KEY HERE\")\n",
        "# project = rf.workspace(\"luca-dalcanto-lrlwg\").project(\"chess-piece-detector-sv3nm\")\n",
        "# dataset = project.version(4).download(\"folder\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkQGDwIvsIkE",
        "outputId": "b650e912-f552-4748-bf97-4ad2c7873a1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.19)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.18.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.47.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the dataset name to the environment so we can use it in a system call later\n",
        "dataset_name = dataset.location.split(os.sep)[-1]\n",
        "os.environ[\"Chess-Piece-Detector-4\"] = dataset_name"
      ],
      "metadata": {
        "id": "Qo0nMZOCsX2H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../yolov5\n",
        "!python classify/train.py --model yolov5m-cls.pt --data Chess-Piece-Detector-4 --epochs 40 --img 224 --pretrained weights/yolov5m-cls.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz6Dk1UKsvwJ",
        "outputId": "c65d2bdb-7c11-4ef6-b160-57bf6eb9dcd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2024-02-05 16:53:39.777271: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-05 16:53:39.777327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-05 16:53:39.778775: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5m-cls.pt, data=Chess-Piece-Detector-4, epochs=40, batch_size=64, imgsz=224, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=weights/yolov5m-cls.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-283-g875d9278 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m-cls.pt to yolov5m-cls.pt...\n",
            "100% 24.9M/24.9M [00:01<00:00, 16.9MB/s]\n",
            "\n",
            "Model summary: 212 layers, 11693293 parameters, 11693293 gradients, 30.9 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 46 weight(decay=0.0), 47 weight(decay=5e-05), 47 bias\n",
            "Image sizes 224 train, 224 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-cls/exp2\u001b[0m\n",
            "Starting yolov5m-cls.pt training on Chess-Piece-Detector-4 dataset with 13 classes for 40 epochs...\n",
            "\n",
            "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
            "      1/40     2.16G        1.52        1.58        0.61       0.952: 100% 357/357 [01:31<00:00,  3.91it/s]\n",
            "      2/40     2.71G        1.35        1.92       0.532       0.938: 100% 357/357 [01:28<00:00,  4.03it/s]\n",
            "      3/40     2.71G        1.26        1.23       0.716       0.972: 100% 357/357 [01:28<00:00,  4.05it/s]\n",
            "      4/40     2.71G         1.2         1.2       0.698       0.987: 100% 357/357 [01:29<00:00,  3.98it/s]\n",
            "      5/40     2.71G        1.15        1.21        0.72       0.991: 100% 357/357 [01:29<00:00,  4.00it/s]\n",
            "      6/40     2.71G         1.1        1.67       0.607       0.864: 100% 357/357 [01:28<00:00,  4.06it/s]\n",
            "      7/40     2.71G        1.05       0.894       0.837           1: 100% 357/357 [01:30<00:00,  3.97it/s]\n",
            "      8/40     2.71G        1.01       0.941       0.843       0.997: 100% 357/357 [01:29<00:00,  4.00it/s]\n",
            "      9/40     2.71G       0.981       0.887        0.86           1: 100% 357/357 [01:28<00:00,  4.03it/s]\n",
            "     10/40     2.71G       0.937        1.16       0.729       0.982: 100% 357/357 [01:28<00:00,  4.03it/s]\n",
            "     11/40     2.71G       0.914        0.76        0.92           1: 100% 357/357 [01:29<00:00,  4.00it/s]\n",
            "     12/40     2.71G        0.89       0.787       0.925       0.998: 100% 357/357 [01:29<00:00,  4.00it/s]\n",
            "     13/40     2.71G        0.87       0.852       0.865       0.996: 100% 357/357 [01:29<00:00,  4.01it/s]\n",
            "     14/40     2.71G       0.882                                    :   7% 26/357 [00:05<01:14,  4.43it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/classify/train.py\", line 370, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/classify/train.py\", line 356, in main\n",
            "    train(opt, device)\n",
            "  File \"/content/yolov5/classify/train.py\", line 226, in train\n",
            "    scaler.step(optimizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 416, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 314, in _maybe_opt_step\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\", line 314, in <genexpr>\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights /content/yolov5/runs/train-cls/exp2/weights/best.pt --source /content/somePiece.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzjKQfvRs8mF",
        "outputId": "ebb07789-f2bd-4aad-dd12-5898349df0bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['/content/yolov5/runs/train-cls/exp2/weights/best.pt'], source=/content/somePiece.png, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-283-g875d9278 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/classify/predict.py\", line 238, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/classify/predict.py\", line 233, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/classify/predict.py\", line 102, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 370, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 78, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/runs/train-cls/exp2/weights/best.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights yolov5s-cls.pt resnet50.pt efficientnet_b0.pt --include onnx engine --img 224"
      ],
      "metadata": {
        "id": "0mX3DNYDLsrk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}